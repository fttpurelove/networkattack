{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TextGenerationPipeline, AutoModelForCausalLM, LlamaTokenizerFast, AutoModelForSequenceClassification\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-uncased\", trust_remote_code=True, num_labels=105).cuda()\n",
    "tokenizer: LlamaTokenizerFast = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# from accelerate import Accelerator\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from typing import Dict, Optional, Sequence\n",
    "\n",
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"<s>\"\n",
    "DEFAULT_UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "def smart_tokenizer_and_embedding_resize(\n",
    "    special_tokens_dict: Dict,\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    "    model: transformers.PreTrainedModel,\n",
    "):\n",
    "    \"\"\"Resize tokenizer and embedding.\n",
    "\n",
    "    Note: This is the unoptimized version that may make your embedding size not be divisible by 64.\n",
    "    \"\"\"\n",
    "    num_new_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if num_new_tokens > 0:\n",
    "        input_embeddings = model.get_input_embeddings().weight.data\n",
    "        # output_embeddings = model.get_output_embeddings().weight.data\n",
    "\n",
    "        input_embeddings_avg = input_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
    "        # output_embeddings_avg = output_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
    "\n",
    "        input_embeddings[-num_new_tokens:] = input_embeddings_avg\n",
    "        # output_embeddings[-num_new_tokens:] = output_embeddings_avg\n",
    "\n",
    "def get_special_tokens_dict(tokenizer):\n",
    "    special_tokens_dict = dict()\n",
    "    if tokenizer.pad_token is None:\n",
    "        special_tokens_dict[\"pad_token\"] = DEFAULT_PAD_TOKEN\n",
    "    if tokenizer.eos_token is None:\n",
    "        special_tokens_dict[\"eos_token\"] = DEFAULT_EOS_TOKEN\n",
    "    if tokenizer.bos_token is None:\n",
    "        special_tokens_dict[\"bos_token\"] = DEFAULT_BOS_TOKEN\n",
    "    if tokenizer.unk_token is None:\n",
    "        special_tokens_dict[\"unk_token\"] = DEFAULT_UNK_TOKEN\n",
    "    return special_tokens_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens_dict = get_special_tokens_dict(tokenizer)\n",
    "smart_tokenizer_and_embedding_resize(\n",
    "    special_tokens_dict=special_tokens_dict,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.columns)\n",
    "# print(len(data))\n",
    "# print(data.iloc[0])\n",
    "# for d in data.iloc[0]:\n",
    "#     print(type(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # å‡è®¾dataæ˜¯ä¸€ä¸ªpandas DataFrameï¼Œå¹¶ä¸”å·²ç»åŠ è½½äº†ç›¸åº”çš„æ•°æ®\n",
    "# # ç»Ÿè®¡Labelåˆ—ä¸­ä¸åŒæ ‡ç­¾çš„æ•°é‡\n",
    "# label_counts = data['Label'].value_counts()\n",
    "# # è·å–ä¸åŒæ ‡ç­¾çš„åˆ—è¡¨\n",
    "# unique_labels = label_counts.index.tolist()\n",
    "# print(unique_labels)\n",
    "# print(len(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # å‡è®¾ data æ˜¯ä¸€ä¸ªå·²ç»å­˜åœ¨çš„ pandas DataFrame\n",
    "\n",
    "# # æ£€æŸ¥ 'TextData' åˆ—æ˜¯å¦å…¨ä¸ºéç©ºå­—ç¬¦ä¸²\n",
    "# all_strings = data['TextData'].apply(lambda x: isinstance(x, str) and x.strip() != '').all()\n",
    "\n",
    "# # æ£€æŸ¥ 'LabelIndex' åˆ—æ˜¯å¦éƒ½ä¸º int\n",
    "# all_ints = data['LabelIndex'].apply(lambda x: isinstance(x, int) and not pd.isnull(x)).all()\n",
    "\n",
    "# # æ‰“å°ç»“æœ\n",
    "# print(\"'TextData' æ˜¯å¦å…¨ä¸ºéç©ºå­—ç¬¦ä¸²:\", all_strings)\n",
    "# print(\"'LabelIndex' æ˜¯å¦éƒ½ä¸º int:\", all_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification, EvalPrediction\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits, labels = torch.tensor(logits), torch.tensor(labels)\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions, zero_division=0, average=\"weighted\")\n",
    "    return {'accuracy': accuracy, 'recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# å®šä¹‰è®­ç»ƒå‚æ•°\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/opt/tiger/network/results',          # è¾“å‡ºç›®å½•\n",
    "    num_train_epochs=1,              # è®­ç»ƒè½®æ•°\n",
    "    per_device_train_batch_size=32,  # è®­ç»ƒæ—¶æ¯ä¸ªè®¾å¤‡çš„batch size\n",
    "    per_device_eval_batch_size=800,   # è¯„ä¼°æ—¶çš„batch size\n",
    "    warmup_steps=500,                # é¢„çƒ­æ­¥æ•°\n",
    "    weight_decay=0.01,               # æƒé‡è¡°å‡\n",
    "    logging_dir='./logs',            # æ—¥å¿—ç›®å½•\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-5,\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy='steps',\n",
    "    save_steps=500,\n",
    "    save_total_limit=3\n",
    ")\n",
    "\n",
    "# å®šä¹‰æ•°æ®å¤„ç†å™¨\n",
    "class CustomDataset:\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([' Destination Port', ' Flow Duration', ' Total Fwd Packets',\n",
      "       ' Total Backward Packets', 'Total Length of Fwd Packets',\n",
      "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max',\n",
      "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean',\n",
      "       ' Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
      "       ' Bwd Packet Length Min', ' Bwd Packet Length Mean',\n",
      "       ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s',\n",
      "       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',\n",
      "       'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max',\n",
      "       ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std',\n",
      "       ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags',\n",
      "       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length',\n",
      "       ' Bwd Header Length', 'Fwd Packets/s', ' Bwd Packets/s',\n",
      "       ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean',\n",
      "       ' Packet Length Std', ' Packet Length Variance', 'FIN Flag Count',\n",
      "       ' SYN Flag Count', ' RST Flag Count', ' PSH Flag Count',\n",
      "       ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count',\n",
      "       ' ECE Flag Count', ' Down/Up Ratio', ' Average Packet Size',\n",
      "       ' Avg Fwd Segment Size', ' Avg Bwd Segment Size',\n",
      "       ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk',\n",
      "       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk',\n",
      "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes',\n",
      "       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
      "       ' Init_Win_bytes_backward', ' act_data_pkt_fwd',\n",
      "       ' min_seg_size_forward', 'Active Mean', ' Active Std', ' Active Max',\n",
      "       ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min',\n",
      "       ' Label'],\n",
      "      dtype='object')\n",
      "54865.0 3.0 2.0 0.0 12.0 0.0 6.0 6.0 6.0 0.0 0.0 0.0 0.0 0.0 4000000.0 666666.6667 3.0 0.0 3.0 3.0 3.0 3.0 0.0 3.0 3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 40.0 0.0 666666.6667 0.0 6.0 6.0 6.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 9.0 6.0 0.0 40.0 0.0 0.0 0.0 0.0 0.0 0.0 2.0 12.0 0.0 0.0 33.0 -1.0 1.0 20.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"/opt/tiger/network_attck/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
    "print(data.columns)\n",
    "# ä½¿ç”¨ apply å‡½æ•°å’Œ lambda è¡¨è¾¾å¼å¯¹æ¯ä¸€è¡Œè¿›è¡Œå¤„ç†\n",
    "# join æ–¹æ³•å°†åˆ—å€¼é€šè¿‡ç©ºæ ¼è¿æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²\n",
    "data['combined_columns'] = data.drop(columns=[' Label']).apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
    "\n",
    "# æŸ¥çœ‹ç»“æœ\n",
    "print(data['combined_columns'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BENIGN', 'DDoS'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# å°†Labelåˆ—è½¬æ¢ä¸ºæ•´æ•°ç´¢å¼•\n",
    "data['LabelIndex'], unique_labels = pd.factorize(data[' Label'])\n",
    "print(unique_labels)\n",
    "data.to_csv(\"processed_ddos_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡†å¤‡æ•°æ®é›†\n",
    "texts = data['combined_columns'].tolist()  # ç”¨å®é™…çš„æ–‡æœ¬åˆ—åæ›¿æ¢'YourTextColumn'\n",
    "labels = data['LabelIndex'].tolist()\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2)\n",
    "\n",
    "# åˆ›å»ºæ•°æ®é›†å®ä¾‹\n",
    "train_dataset = CustomDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = CustomDataset(test_texts, test_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ä¿å­˜ train_dataset\n",
    "torch.save({\n",
    "    'texts': train_texts,\n",
    "    'labels': train_labels,\n",
    "}, '/opt/tiger/network_attck/ddos_train_dataset.pt')\n",
    "\n",
    "# ä¿å­˜ test_dataset\n",
    "torch.save({\n",
    "    'texts': test_texts,\n",
    "    'labels': test_labels,\n",
    "}, '/opt/tiger/network_attck/ddos_test_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = torch.load(\"train_dataset.pt\"), torch.load(\"test_dataset.pt\")\n",
    "train_texts, train_labels = train[\"texts\"], train[\"labels\"]\n",
    "test_texts, test_labels = test[\"texts\"], test[\"labels\"]\n",
    "train_dataset = CustomDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = CustomDataset(test_texts, test_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.143, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ–Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,  # ä¼ å…¥æµ‹è¯•æ•°æ®é›†\n",
    "    compute_metrics=compute_metrics,  # æŒ‡å®šè®¡ç®—æŒ‡æ ‡çš„å‡½æ•°\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: â­ï¸ View project at https://ml.byteintl.net/experiment/tracking/detail?Id=project_20230423_c364971e\n",
      "wandb: ğŸš€ View run at https://ml.byteintl.net/experiment/tracking/detail?Id=project_20230423_c364971e&selectedTrial=run_20240508_e07025be\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4fdb1074ac4dc8b5f5fc39609eac2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668659200270972, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.72"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/tiger/network_attck/wandb/run-20240508_114615-run_20240508_e07025be</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"\" target=\"_blank\"></a></strong> to <a href=\"\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n192-024-074:274544:274544 [0] NCCL INFO cudaDriverVersion 12010\n",
      "n192-024-074:274544:274544 [0] NCCL INFO NCCL_SOCKET_FAMILY set by environment to AF_INET6\n",
      "n192-024-074:274544:274544 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\n",
      "n192-024-074:274544:274544 [0] NCCL INFO Bootstrap : Using eth0:fdbd:dc61:7:34::74<0>\n",
      "n192-024-074:274544:274544 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation\n",
      "NCCL version 2.20.5+cuda12.4\n",
      "n192-024-074:274544:278781 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.\n",
      "n192-024-074:274544:278781 [2] NCCL INFO NCCL_SOCKET_FAMILY set by environment to AF_INET6\n",
      "n192-024-074:274544:278781 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\n",
      "n192-024-074:274544:278781 [2] NCCL INFO NCCL_IB_HCA set to mlx5_2:1\n",
      "n192-024-074:274544:278781 [2] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [RO]; OOB eth0:fdbd:dc61:7:34::74<0>\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Using non-device net plugin version 0\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Using network IB\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Using non-device net plugin version 0\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Using network IB\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Using non-device net plugin version 0\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Using network IB\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Using non-device net plugin version 0\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Using network IB\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Using non-device net plugin version 0\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Using network IB\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Using non-device net plugin version 0\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Using network IB\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Using non-device net plugin version 0\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Using network IB\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Using non-device net plugin version 0\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Using network IB\n",
      "n192-024-074:274544:278782 [3] NCCL INFO comm 0x1c00cb30 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3e000 commId 0x70ee1a2c12bc9ec6 - Init START\n",
      "n192-024-074:274544:278780 [1] NCCL INFO comm 0x1bffff60 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 1b000 commId 0x70ee1a2c12bc9ec6 - Init START\n",
      "n192-024-074:274544:278779 [0] NCCL INFO comm 0x1bffa950 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 1a000 commId 0x70ee1a2c12bc9ec6 - Init START\n",
      "n192-024-074:274544:278781 [2] NCCL INFO comm 0x1c006470 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 3d000 commId 0x70ee1a2c12bc9ec6 - Init START\n",
      "n192-024-074:274544:278785 [6] NCCL INFO comm 0x1c01fa60 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId b1000 commId 0x70ee1a2c12bc9ec6 - Init START\n",
      "n192-024-074:274544:278783 [4] NCCL INFO comm 0x1c013040 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 88000 commId 0x70ee1a2c12bc9ec6 - Init START\n",
      "n192-024-074:274544:278784 [5] NCCL INFO comm 0x1c019550 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 89000 commId 0x70ee1a2c12bc9ec6 - Init START\n",
      "n192-024-074:274544:278786 [7] NCCL INFO comm 0x1c025f70 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId b2000 commId 0x70ee1a2c12bc9ec6 - Init START\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\n",
      "n192-024-074:274544:278779 [0] NCCL INFO NVLS multicast support is not available on dev 0\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff\n",
      "n192-024-074:274544:278781 [2] NCCL INFO NVLS multicast support is not available on dev 2\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff\n",
      "n192-024-074:274544:278782 [3] NCCL INFO NVLS multicast support is not available on dev 3\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff\n",
      "n192-024-074:274544:278780 [1] NCCL INFO NVLS multicast support is not available on dev 1\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Setting affinity for GPU 5 to ffffff00,0000ffff,ff000000\n",
      "n192-024-074:274544:278784 [5] NCCL INFO NVLS multicast support is not available on dev 5\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Setting affinity for GPU 4 to ffffff00,0000ffff,ff000000\n",
      "n192-024-074:274544:278783 [4] NCCL INFO NVLS multicast support is not available on dev 4\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Setting affinity for GPU 7 to ffffff00,0000ffff,ff000000\n",
      "n192-024-074:274544:278786 [7] NCCL INFO NVLS multicast support is not available on dev 7\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Setting affinity for GPU 6 to ffffff00,0000ffff,ff000000\n",
      "n192-024-074:274544:278785 [6] NCCL INFO NVLS multicast support is not available on dev 6\n",
      "n192-024-074:274544:278785 [6] NCCL INFO comm 0x1c01fa60 rank 6 nRanks 8 nNodes 1 localRanks 8 localRank 6 MNNVL 0\n",
      "n192-024-074:274544:278781 [2] NCCL INFO comm 0x1c006470 rank 2 nRanks 8 nNodes 1 localRanks 8 localRank 2 MNNVL 0\n",
      "n192-024-074:274544:278780 [1] NCCL INFO comm 0x1bffff60 rank 1 nRanks 8 nNodes 1 localRanks 8 localRank 1 MNNVL 0\n",
      "n192-024-074:274544:278786 [7] NCCL INFO comm 0x1c025f70 rank 7 nRanks 8 nNodes 1 localRanks 8 localRank 7 MNNVL 0\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 4/-1/-1->6->1 [2] 1/-1/-1->6->4 [3] 1/-1/-1->6->4 [4] -1/-1/-1->6->1 [5] 5/-1/-1->6->7 [6] 7/-1/-1->6->5 [7] 4/-1/-1->6->1 [8] 1/-1/-1->6->4 [9] 1/-1/-1->6->4 [10] -1/-1/-1->6->1 [11] 5/-1/-1->6->7\n",
      "n192-024-074:274544:278785 [6] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->0 [2] 5/-1/-1->2->0 [3] -1/-1/-1->2->3 [4] 1/-1/-1->2->3 [5] 0/-1/-1->2->5 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->0 [8] 5/-1/-1->2->0 [9] -1/-1/-1->2->3 [10] 1/-1/-1->2->3 [11] 0/-1/-1->2->5\n",
      "n192-024-074:274544:278783 [4] NCCL INFO comm 0x1c013040 rank 4 nRanks 8 nNodes 1 localRanks 8 localRank 4 MNNVL 0\n",
      "n192-024-074:274544:278784 [5] NCCL INFO comm 0x1c019550 rank 5 nRanks 8 nNodes 1 localRanks 8 localRank 5 MNNVL 0\n",
      "n192-024-074:274544:278779 [0] NCCL INFO comm 0x1bffa950 rank 0 nRanks 8 nNodes 1 localRanks 8 localRank 0 MNNVL 0\n",
      "n192-024-074:274544:278782 [3] NCCL INFO comm 0x1c00cb30 rank 3 nRanks 8 nNodes 1 localRanks 8 localRank 3 MNNVL 0\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->5 [2] 4/-1/-1->7->5 [3] 5/-1/-1->7->0 [4] 5/-1/-1->7->0 [5] 6/-1/-1->7->4 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->5 [8] 4/-1/-1->7->5 [9] 5/-1/-1->7->0 [10] 5/-1/-1->7->0 [11] 6/-1/-1->7->4\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 6/-1/-1->1->3 [2] 3/-1/-1->1->6 [3] 3/-1/-1->1->6 [4] 6/-1/-1->1->2 [5] -1/-1/-1->1->3 [6] 2/-1/-1->1->0 [7] 6/-1/-1->1->3 [8] 3/-1/-1->1->6 [9] 3/-1/-1->1->6 [10] 6/-1/-1->1->2 [11] -1/-1/-1->1->3\n",
      "n192-024-074:274544:278786 [7] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->6 [2] 6/-1/-1->4->7 [3] 6/-1/-1->4->5 [4] 3/-1/-1->4->5 [5] 7/-1/-1->4->-1 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->6 [8] 6/-1/-1->4->7 [9] 6/-1/-1->4->5 [10] 3/-1/-1->4->5 [11] 7/-1/-1->4->-1\n",
      "n192-024-074:274544:278781 [2] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 1/-1/-1->3->2 [2] -1/-1/-1->3->1 [3] 2/-1/-1->3->1 [4] 2/-1/-1->3->4 [5] 1/-1/-1->3->0 [6] 4/-1/-1->3->2 [7] 1/-1/-1->3->2 [8] -1/-1/-1->3->1 [9] 2/-1/-1->3->1 [10] 2/-1/-1->3->4 [11] 1/-1/-1->3->0\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 7/-1/-1->5->4 [2] 7/-1/-1->5->2 [3] 4/-1/-1->5->7 [4] 4/-1/-1->5->7 [5] 2/-1/-1->5->6 [6] 6/-1/-1->5->4 [7] 7/-1/-1->5->4 [8] 7/-1/-1->5->2 [9] 4/-1/-1->5->7 [10] 4/-1/-1->5->7 [11] 2/-1/-1->5->6\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 00/12 :    0   1   2   3   4   5   6   7\n",
      "n192-024-074:274544:278782 [3] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-024-074:274544:278784 [5] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-024-074:274544:278783 [4] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 01/12 :    0   2   3   1   6   4   5   7\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 02/12 :    0   2   5   7   4   6   1   3\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 03/12 :    0   7   5   4   6   1   3   2\n",
      "n192-024-074:274544:278780 [1] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 04/12 :    0   7   6   5   4   3   2   1\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 05/12 :    0   3   1   6   4   7   5   2\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 06/12 :    0   1   2   3   4   5   6   7\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 07/12 :    0   2   3   1   6   4   5   7\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 08/12 :    0   2   5   7   4   6   1   3\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 09/12 :    0   7   5   4   6   1   3   2\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 10/12 :    0   7   6   5   4   3   2   1\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 11/12 :    0   3   1   6   4   7   5   2\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 2/-1/-1->0->-1 [2] 2/-1/-1->0->-1 [3] 7/-1/-1->0->-1 [4] 7/-1/-1->0->-1 [5] 3/-1/-1->0->2 [6] 1/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 2/-1/-1->0->-1 [9] 7/-1/-1->0->-1 [10] 7/-1/-1->0->-1 [11] 3/-1/-1->0->2\n",
      "n192-024-074:274544:278779 [0] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 00/0 : 6[6] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 00/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 06/0 : 6[6] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 01/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 06/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 07/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 06/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 06/0 : 5[5] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 07/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 06/0 : 3[3] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 01/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 02/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 01/0 : 0[0] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 02/0 : 4[4] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 02/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 03/0 : 4[4] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 07/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 08/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 07/0 : 0[0] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 08/0 : 4[4] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 08/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 09/0 : 4[4] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 02/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 05/0 : 4[4] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 02/0 : 2[2] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 03/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 11/0 : 4[4] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 08/0 : 2[2] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 08/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 02/0 : 7[7] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 02/0 : 3[3] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 05/0 : 5[5] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 09/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 08/0 : 7[7] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 08/0 : 3[3] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 11/0 : 5[5] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 01/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 03/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 01/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 03/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 05/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 05/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 05/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 05/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 07/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 09/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 07/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 09/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 11/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 11/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 11/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 11/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 01/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 05/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 07/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 03/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 03/0 : 0[0] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 11/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 04/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 04/0 : 0[0] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 04/0 : 7[7] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 09/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 09/0 : 0[0] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 10/0 : 7[7] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 10/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 10/0 : 0[0] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 10/0 : 2[2] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 04/0 : 6[6] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 10/0 : 6[6] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 09/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 04/0 : 4[4] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 10/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 10/0 : 4[4] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Connected all rings\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Connected all rings\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Connected all rings\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Connected all rings\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Connected all rings\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Connected all rings\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Connected all rings\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Connected all rings\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 03/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 05/0 : 6[6] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 04/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 03/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 11/0 : 6[6] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 09/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 04/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 05/0 : 5[5] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 04/0 : 3[3] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 10/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 09/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 11/0 : 5[5] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 09/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 10/0 : 3[3] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 10/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 05/0 : 0[0] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 10/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 11/0 : 0[0] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 01/0 : 4[4] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 03/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 05/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 07/0 : 4[4] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 04/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 05/0 : 2[2] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 01/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 02/0 : 4[4] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 09/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 11/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 11/0 : 2[2] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 04/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 08/0 : 4[4] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 10/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 07/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 05/0 : 3[3] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 10/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 11/0 : 3[3] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 05/0 : 7[7] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 02/0 : 5[5] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 03/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 11/0 : 7[7] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 08/0 : 5[5] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 01/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 09/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 02/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 02/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 04/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 02/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 07/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 03/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 08/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 08/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 04/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 10/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 08/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 09/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 10/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 00/0 : 7[7] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 05/0 : 7[7] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 02/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 06/0 : 7[7] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 03/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 11/0 : 7[7] -> 6[6] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 08/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 09/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 06/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 07/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 00/0 : 6[6] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 05/0 : 6[6] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 06/0 : 4[4] -> 3[3] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 06/0 : 6[6] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 11/0 : 6[6] -> 5[5] via P2P/direct pointer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Connected all trees\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Connected all trees\n",
      "n192-024-074:274544:278786 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-024-074:274544:278786 [7] NCCL INFO 12 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 04/1 : 7[7] -> 1[1] via P2P/indirect/6[6]\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Connected all trees\n",
      "n192-024-074:274544:278779 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Connected all trees\n",
      "n192-024-074:274544:278783 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-024-074:274544:278783 [4] NCCL INFO 12 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-024-074:274544:278779 [0] NCCL INFO 12 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-024-074:274544:278780 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-024-074:274544:278780 [1] NCCL INFO 12 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Connected all trees\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Connected all trees\n",
      "n192-024-074:274544:278785 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-024-074:274544:278782 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Connected all trees\n",
      "n192-024-074:274544:278782 [3] NCCL INFO 12 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-024-074:274544:278785 [6] NCCL INFO 12 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-024-074:274544:278781 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-024-074:274544:278781 [2] NCCL INFO 12 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Connected all trees\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 04/1 : 6[6] -> 0[0] via P2P/indirect/7[7]\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 04/1 : 2[2] -> 4[4] via P2P/indirect/5[5]\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 04/1 : 3[3] -> 5[5] via P2P/indirect/4[4]\n",
      "n192-024-074:274544:278784 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-024-074:274544:278784 [5] NCCL INFO 12 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 05/1 : 7[7] -> 1[1] via P2P/indirect/6[6]\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 05/1 : 3[3] -> 5[5] via P2P/indirect/4[4]\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 05/1 : 2[2] -> 4[4] via P2P/indirect/5[5]\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 05/1 : 6[6] -> 0[0] via P2P/indirect/7[7]\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 12/1 : 7[7] -> 2[2] via P2P/indirect/0[0]\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 12/1 : 1[1] -> 4[4] via P2P/indirect/6[6]\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 12/1 : 3[3] -> 6[6] via P2P/indirect/1[1]\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 12/1 : 5[5] -> 0[0] via P2P/indirect/7[7]\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 13/1 : 1[1] -> 4[4] via P2P/indirect/6[6]\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 13/1 : 5[5] -> 0[0] via P2P/indirect/7[7]\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 13/1 : 7[7] -> 2[2] via P2P/indirect/0[0]\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 13/1 : 3[3] -> 6[6] via P2P/indirect/1[1]\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 02/1 : 2[2] -> 6[6] via P2P/indirect/1[1]\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 02/1 : 4[4] -> 0[0] via P2P/indirect/7[7]\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 02/1 : 0[0] -> 4[4] via P2P/indirect/3[3]\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 02/1 : 6[6] -> 2[2] via P2P/indirect/5[5]\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 02/1 : 7[7] -> 3[3] via P2P/indirect/0[0]\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 02/1 : 1[1] -> 5[5] via P2P/indirect/6[6]\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 03/1 : 2[2] -> 6[6] via P2P/indirect/1[1]\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 03/1 : 4[4] -> 0[0] via P2P/indirect/7[7]\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 03/1 : 6[6] -> 2[2] via P2P/indirect/5[5]\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 02/1 : 5[5] -> 1[1] via P2P/indirect/6[6]\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 02/1 : 3[3] -> 7[7] via P2P/indirect/0[0]\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 03/1 : 0[0] -> 4[4] via P2P/indirect/3[3]\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 03/1 : 1[1] -> 5[5] via P2P/indirect/6[6]\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 10/1 : 2[2] -> 7[7] via P2P/indirect/0[0]\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 10/1 : 6[6] -> 3[3] via P2P/indirect/1[1]\n",
      "n192-024-074:274544:278786 [7] NCCL INFO Channel 03/1 : 7[7] -> 3[3] via P2P/indirect/0[0]\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 03/1 : 5[5] -> 1[1] via P2P/indirect/6[6]\n",
      "n192-024-074:274544:278782 [3] NCCL INFO Channel 03/1 : 3[3] -> 7[7] via P2P/indirect/0[0]\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 10/1 : 4[4] -> 1[1] via P2P/indirect/6[6]\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 10/1 : 0[0] -> 5[5] via P2P/indirect/7[7]\n",
      "n192-024-074:274544:278785 [6] NCCL INFO Channel 11/1 : 6[6] -> 3[3] via P2P/indirect/1[1]\n",
      "n192-024-074:274544:278781 [2] NCCL INFO Channel 11/1 : 2[2] -> 7[7] via P2P/indirect/0[0]\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 11/1 : 0[0] -> 5[5] via P2P/indirect/7[7]\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 11/1 : 4[4] -> 1[1] via P2P/indirect/6[6]\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 06/1 : 4[4] -> 2[2] via P2P/indirect/3[3]\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 06/1 : 1[1] -> 7[7] via P2P/indirect/0[0]\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 06/1 : 0[0] -> 6[6] via P2P/indirect/1[1]\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 06/1 : 5[5] -> 3[3] via P2P/indirect/2[2]\n",
      "n192-024-074:274544:278783 [4] NCCL INFO Channel 07/1 : 4[4] -> 2[2] via P2P/indirect/3[3]\n",
      "n192-024-074:274544:278784 [5] NCCL INFO Channel 07/1 : 5[5] -> 3[3] via P2P/indirect/2[2]\n",
      "n192-024-074:274544:278780 [1] NCCL INFO Channel 07/1 : 1[1] -> 7[7] via P2P/indirect/0[0]\n",
      "n192-024-074:274544:278779 [0] NCCL INFO Channel 07/1 : 0[0] -> 6[6] via P2P/indirect/1[1]\n",
      "n192-024-074:274544:278780 [1] NCCL INFO comm 0x1bffff60 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 1b000 commId 0x70ee1a2c12bc9ec6 - Init COMPLETE\n",
      "n192-024-074:274544:278782 [3] NCCL INFO comm 0x1c00cb30 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3e000 commId 0x70ee1a2c12bc9ec6 - Init COMPLETE\n",
      "n192-024-074:274544:278786 [7] NCCL INFO comm 0x1c025f70 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId b2000 commId 0x70ee1a2c12bc9ec6 - Init COMPLETE\n",
      "n192-024-074:274544:278784 [5] NCCL INFO comm 0x1c019550 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 89000 commId 0x70ee1a2c12bc9ec6 - Init COMPLETE\n",
      "n192-024-074:274544:278781 [2] NCCL INFO comm 0x1c006470 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 3d000 commId 0x70ee1a2c12bc9ec6 - Init COMPLETE\n",
      "n192-024-074:274544:278785 [6] NCCL INFO comm 0x1c01fa60 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId b1000 commId 0x70ee1a2c12bc9ec6 - Init COMPLETE\n",
      "n192-024-074:274544:278779 [0] NCCL INFO comm 0x1bffa950 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 1a000 commId 0x70ee1a2c12bc9ec6 - Init COMPLETE\n",
      "n192-024-074:274544:278783 [4] NCCL INFO comm 0x1c013040 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 88000 commId 0x70ee1a2c12bc9ec6 - Init COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='706' max='706' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [706/706 13:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.646600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.600200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.498300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.390200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.980700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.896800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.788700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.643300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.853600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.625600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.455500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.307400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.879800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.739500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.612400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.289500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.099800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.938100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.800500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.678500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.570900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.486500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.381200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.303700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.262400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.205400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.168400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.131700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.082100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.040700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.039200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.029800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.014800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.009900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=706, training_loss=1.1023860729112165, metrics={'train_runtime': 843.7685, 'train_samples_per_second': 214.035, 'train_steps_per_second': 0.837, 'total_flos': 4.756074747756134e+16, 'train_loss': 1.1023860729112165, 'epoch': 1.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f4f5f9b88b0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f4e5c7592e0, execution_count=14 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f4e5c759790, raw_cell=\"# å¼€å§‹è®­ç»ƒ\n",
      "trainer.train()\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://arnold-proxy-i18n.tiktok-row.org/opt/tiger/network_attck/train_ddos_LLM.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D> result=TrainOutput(global_step=706, training_loss=1.1023860729112165, metrics={'train_runtime': 843.7685, 'train_samples_per_second': 214.035, 'train_steps_per_second': 0.837, 'total_flos': 4.756074747756134e+16, 'train_loss': 1.1023860729112165, 'epoch': 1.0})>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# å¼€å§‹è®­ç»ƒ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f4f5f9b88b0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f4e76bd79a0, raw_cell=\"trainer.evaluate()\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://arnold-proxy-i18n.tiktok-row.org/opt/tiger/network_attck/train_ddos_LLM.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 01:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.008646111004054546,\n",
       " 'eval_accuracy': 0.9994241289951051,\n",
       " 'eval_recall': 0.9994241289951051,\n",
       " 'eval_runtime': 91.2101,\n",
       " 'eval_samples_per_second': 495.0,\n",
       " 'eval_steps_per_second': 0.088,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f4f5f9b88b0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f4e76bd7460, execution_count=15 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f4e76bd79a0, raw_cell=\"trainer.evaluate()\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://arnold-proxy-i18n.tiktok-row.org/opt/tiger/network_attck/train_ddos_LLM.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D> result={'eval_loss': 0.008646111004054546, 'eval_accuracy': 0.9994241289951051, 'eval_recall': 0.9994241289951051, 'eval_runtime': 91.2101, 'eval_samples_per_second': 495.0, 'eval_steps_per_second': 0.088, 'epoch': 1.0}>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
