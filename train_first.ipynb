{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TextGenerationPipeline, AutoModelForCausalLM, LlamaTokenizerFast, AutoModelForSequenceClassification\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e90f14c3ff4b5dbe8b5e80c9f761e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fdfab2b2e64c4998263af9dad285e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3996cca7321b4c4594a233126c47c7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7c290e49554a4dbd905c9f5388b85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b8dcc6b9dd4fdf99551154bc408e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-uncased\", trust_remote_code=True, num_labels=105).cuda()\n",
    "tokenizer: LlamaTokenizerFast = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# from accelerate import Accelerator\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from typing import Dict, Optional, Sequence\n",
    "\n",
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"<s>\"\n",
    "DEFAULT_UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "def smart_tokenizer_and_embedding_resize(\n",
    "    special_tokens_dict: Dict,\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    "    model: transformers.PreTrainedModel,\n",
    "):\n",
    "    \"\"\"Resize tokenizer and embedding.\n",
    "\n",
    "    Note: This is the unoptimized version that may make your embedding size not be divisible by 64.\n",
    "    \"\"\"\n",
    "    num_new_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if num_new_tokens > 0:\n",
    "        input_embeddings = model.get_input_embeddings().weight.data\n",
    "        # output_embeddings = model.get_output_embeddings().weight.data\n",
    "\n",
    "        input_embeddings_avg = input_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
    "        # output_embeddings_avg = output_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
    "\n",
    "        input_embeddings[-num_new_tokens:] = input_embeddings_avg\n",
    "        # output_embeddings[-num_new_tokens:] = output_embeddings_avg\n",
    "\n",
    "def get_special_tokens_dict(tokenizer):\n",
    "    special_tokens_dict = dict()\n",
    "    if tokenizer.pad_token is None:\n",
    "        special_tokens_dict[\"pad_token\"] = DEFAULT_PAD_TOKEN\n",
    "    if tokenizer.eos_token is None:\n",
    "        special_tokens_dict[\"eos_token\"] = DEFAULT_EOS_TOKEN\n",
    "    if tokenizer.bos_token is None:\n",
    "        special_tokens_dict[\"bos_token\"] = DEFAULT_BOS_TOKEN\n",
    "    if tokenizer.unk_token is None:\n",
    "        special_tokens_dict[\"unk_token\"] = DEFAULT_UNK_TOKEN\n",
    "    return special_tokens_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens_dict = get_special_tokens_dict(tokenizer)\n",
    "smart_tokenizer_and_embedding_resize(\n",
    "    special_tokens_dict=special_tokens_dict,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.columns)\n",
    "# print(len(data))\n",
    "# print(data.iloc[0])\n",
    "# for d in data.iloc[0]:\n",
    "#     print(type(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 假设data是一个pandas DataFrame，并且已经加载了相应的数据\n",
    "# # 统计Label列中不同标签的数量\n",
    "# label_counts = data['Label'].value_counts()\n",
    "# # 获取不同标签的列表\n",
    "# unique_labels = label_counts.index.tolist()\n",
    "# print(unique_labels)\n",
    "# print(len(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将Label列转换为整数索引\n",
    "# data['LabelIndex'], unique_labels = pd.factorize(data['Label'])\n",
    "# print(unique_labels)\n",
    "# data.to_csv(\"processed_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 假设 data 是一个已经存在的 pandas DataFrame\n",
    "\n",
    "# # 检查 'TextData' 列是否全为非空字符串\n",
    "# all_strings = data['TextData'].apply(lambda x: isinstance(x, str) and x.strip() != '').all()\n",
    "\n",
    "# # 检查 'LabelIndex' 列是否都为 int\n",
    "# all_ints = data['LabelIndex'].apply(lambda x: isinstance(x, int) and not pd.isnull(x)).all()\n",
    "\n",
    "# # 打印结果\n",
    "# print(\"'TextData' 是否全为非空字符串:\", all_strings)\n",
    "# print(\"'LabelIndex' 是否都为 int:\", all_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification, EvalPrediction\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits, labels = torch.tensor(logits), torch.tensor(labels)\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions, zero_division=0, average=\"weighted\")\n",
    "    return {'accuracy': accuracy, 'recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/opt/tiger/network/results',          # 输出目录\n",
    "    num_train_epochs=1,              # 训练轮数\n",
    "    per_device_train_batch_size=32,  # 训练时每个设备的batch size\n",
    "    per_device_eval_batch_size=800,   # 评估时的batch size\n",
    "    warmup_steps=500,                # 预热步数\n",
    "    weight_decay=0.01,               # 权重衰减\n",
    "    logging_dir='./logs',            # 日志目录\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-5,\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy='steps',\n",
    "    save_steps=500,\n",
    "    save_total_limit=3\n",
    ")\n",
    "\n",
    "# 定义数据处理器\n",
    "class CustomDataset:\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# data = pd.read_csv(\"processed_csv.csv\")\n",
    "# # 准备数据集\n",
    "# texts = data['TextData'].tolist()  # 用实际的文本列名替换'YourTextColumn'\n",
    "# labels = data['LabelIndex'].tolist()\n",
    "\n",
    "# # 划分训练集和验证集\n",
    "# train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2)\n",
    "\n",
    "# # 创建数据集实例\n",
    "# train_dataset = CustomDataset(train_texts, train_labels, tokenizer)\n",
    "# test_dataset = CustomDataset(test_texts, test_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd134c994f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fd122a8fa90, raw_cell=\"import torch\n",
      "\n",
      "# 保存 train_dataset\n",
      "torch.save({\n",
      "    ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://arnold-proxy-i18n.tiktok-row.org/opt/tiger/network_attck/fcbank.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd134c994f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fd122a8fb20, execution_count=14 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fd122a8fa90, raw_cell=\"import torch\n",
      "\n",
      "# 保存 train_dataset\n",
      "torch.save({\n",
      "    ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://arnold-proxy-i18n.tiktok-row.org/opt/tiger/network_attck/fcbank.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "# # 保存 train_dataset\n",
    "# torch.save({\n",
    "#     'texts': train_texts,\n",
    "#     'labels': train_labels,\n",
    "# }, '/opt/tiger/network_attck/train_dataset.pt')\n",
    "\n",
    "# # 保存 test_dataset\n",
    "# torch.save({\n",
    "#     'texts': test_texts,\n",
    "#     'labels': test_labels,\n",
    "# }, '/opt/tiger/network_attck/test_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = torch.load(\"train_dataset.pt\"), torch.load(\"test_dataset.pt\")\n",
    "train_texts, train_labels = train[\"texts\"], train[\"labels\"]\n",
    "test_texts, test_labels = test[\"texts\"], test[\"labels\"]\n",
    "train_dataset = CustomDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = CustomDataset(test_texts, test_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.143, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# 初始化Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,  # 传入测试数据集\n",
    "    compute_metrics=compute_metrics,  # 指定计算指标的函数\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 开始训练\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n192-025-207:289013:289013 [0] NCCL INFO cudaDriverVersion 12010\n",
      "n192-025-207:289013:289013 [0] NCCL INFO NCCL_SOCKET_FAMILY set by environment to AF_INET6\n",
      "n192-025-207:289013:289013 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\n",
      "n192-025-207:289013:289013 [0] NCCL INFO Bootstrap : Using eth0:fdbd:dc61:7:40::207<0>\n",
      "n192-025-207:289013:289013 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation\n",
      "NCCL version 2.19.3+cuda12.3\n",
      "n192-025-207:289013:289307 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.\n",
      "n192-025-207:289013:289307 [1] NCCL INFO NCCL_SOCKET_FAMILY set by environment to AF_INET6\n",
      "n192-025-207:289013:289307 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\n",
      "n192-025-207:289013:289307 [1] NCCL INFO NCCL_IB_HCA set to mlx5_2:1\n",
      "n192-025-207:289013:289307 [1] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [RO]; OOB eth0:fdbd:dc61:7:40::207<0>\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Using non-device net plugin version 0\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Using network IB\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Using non-device net plugin version 0\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Using network IB\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Using non-device net plugin version 0\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Using network IB\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Using non-device net plugin version 0\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Using network IB\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Using non-device net plugin version 0\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Using network IB\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Using non-device net plugin version 0\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Using network IB\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Using non-device net plugin version 0\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Using network IB\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Using non-device net plugin version 0\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Using network IB\n",
      "n192-025-207:289013:289311 [5] NCCL INFO comm 0x18191f80 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 89000 commId 0x813af0a1d5470656 - Init START\n",
      "n192-025-207:289013:289310 [4] NCCL INFO comm 0x1818c080 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 88000 commId 0x813af0a1d5470656 - Init START\n",
      "n192-025-207:289013:289309 [3] NCCL INFO comm 0x18186180 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3e000 commId 0x813af0a1d5470656 - Init START\n",
      "n192-025-207:289013:289308 [2] NCCL INFO comm 0x181801f0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 3d000 commId 0x813af0a1d5470656 - Init START\n",
      "n192-025-207:289013:289307 [1] NCCL INFO comm 0x1817a2f0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 1b000 commId 0x813af0a1d5470656 - Init START\n",
      "n192-025-207:289013:289312 [6] NCCL INFO comm 0x18197e80 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId b1000 commId 0x813af0a1d5470656 - Init START\n",
      "n192-025-207:289013:289313 [7] NCCL INFO comm 0x1819dd80 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId b2000 commId 0x813af0a1d5470656 - Init START\n",
      "n192-025-207:289013:289306 [0] NCCL INFO comm 0x181752f0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 1a000 commId 0x813af0a1d5470656 - Init START\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\n",
      "n192-025-207:289013:289306 [0] NCCL INFO NVLS multicast support is not available on dev 0\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Setting affinity for GPU 5 to ffffff00,0000ffff,ff000000\n",
      "n192-025-207:289013:289311 [5] NCCL INFO NVLS multicast support is not available on dev 5\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff\n",
      "n192-025-207:289013:289307 [1] NCCL INFO NVLS multicast support is not available on dev 1\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Setting affinity for GPU 4 to ffffff00,0000ffff,ff000000\n",
      "n192-025-207:289013:289310 [4] NCCL INFO NVLS multicast support is not available on dev 4\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Setting affinity for GPU 6 to ffffff00,0000ffff,ff000000\n",
      "n192-025-207:289013:289312 [6] NCCL INFO NVLS multicast support is not available on dev 6\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Setting affinity for GPU 7 to ffffff00,0000ffff,ff000000\n",
      "n192-025-207:289013:289313 [7] NCCL INFO NVLS multicast support is not available on dev 7\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff\n",
      "n192-025-207:289013:289309 [3] NCCL INFO NVLS multicast support is not available on dev 3\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff\n",
      "n192-025-207:289013:289308 [2] NCCL INFO NVLS multicast support is not available on dev 2\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->0 [2] 5/-1/-1->2->0 [3] -1/-1/-1->2->3 [4] 1/-1/-1->2->3 [5] 0/-1/-1->2->5 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->0 [8] 5/-1/-1->2->0 [9] -1/-1/-1->2->3 [10] 1/-1/-1->2->3 [11] 0/-1/-1->2->5\n",
      "n192-025-207:289013:289308 [2] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->5 [2] 4/-1/-1->7->5 [3] 5/-1/-1->7->0 [4] 5/-1/-1->7->0 [5] 6/-1/-1->7->4 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->5 [8] 4/-1/-1->7->5 [9] 5/-1/-1->7->0 [10] 5/-1/-1->7->0 [11] 6/-1/-1->7->4\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->6 [2] 6/-1/-1->4->7 [3] 6/-1/-1->4->5 [4] 3/-1/-1->4->5 [5] 7/-1/-1->4->-1 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->6 [8] 6/-1/-1->4->7 [9] 6/-1/-1->4->5 [10] 3/-1/-1->4->5 [11] 7/-1/-1->4->-1\n",
      "n192-025-207:289013:289313 [7] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 1/-1/-1->3->2 [2] -1/-1/-1->3->1 [3] 2/-1/-1->3->1 [4] 2/-1/-1->3->4 [5] 1/-1/-1->3->0 [6] 4/-1/-1->3->2 [7] 1/-1/-1->3->2 [8] -1/-1/-1->3->1 [9] 2/-1/-1->3->1 [10] 2/-1/-1->3->4 [11] 1/-1/-1->3->0\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 6/-1/-1->1->3 [2] 3/-1/-1->1->6 [3] 3/-1/-1->1->6 [4] 6/-1/-1->1->2 [5] -1/-1/-1->1->3 [6] 2/-1/-1->1->0 [7] 6/-1/-1->1->3 [8] 3/-1/-1->1->6 [9] 3/-1/-1->1->6 [10] 6/-1/-1->1->2 [11] -1/-1/-1->1->3\n",
      "n192-025-207:289013:289309 [3] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-025-207:289013:289310 [4] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 00/12 :    0   1   2   3   4   5   6   7\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 4/-1/-1->6->1 [2] 1/-1/-1->6->4 [3] 1/-1/-1->6->4 [4] -1/-1/-1->6->1 [5] 5/-1/-1->6->7 [6] 7/-1/-1->6->5 [7] 4/-1/-1->6->1 [8] 1/-1/-1->6->4 [9] 1/-1/-1->6->4 [10] -1/-1/-1->6->1 [11] 5/-1/-1->6->7\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 7/-1/-1->5->4 [2] 7/-1/-1->5->2 [3] 4/-1/-1->5->7 [4] 4/-1/-1->5->7 [5] 2/-1/-1->5->6 [6] 6/-1/-1->5->4 [7] 7/-1/-1->5->4 [8] 7/-1/-1->5->2 [9] 4/-1/-1->5->7 [10] 4/-1/-1->5->7 [11] 2/-1/-1->5->6\n",
      "n192-025-207:289013:289307 [1] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-025-207:289013:289312 [6] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-025-207:289013:289311 [5] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 01/12 :    0   2   3   1   6   4   5   7\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 02/12 :    0   2   5   7   4   6   1   3\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 03/12 :    0   7   5   4   6   1   3   2\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 04/12 :    0   7   6   5   4   3   2   1\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 05/12 :    0   3   1   6   4   7   5   2\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 06/12 :    0   1   2   3   4   5   6   7\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 07/12 :    0   2   3   1   6   4   5   7\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 08/12 :    0   2   5   7   4   6   1   3\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 09/12 :    0   7   5   4   6   1   3   2\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 10/12 :    0   7   6   5   4   3   2   1\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 11/12 :    0   3   1   6   4   7   5   2\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 2/-1/-1->0->-1 [2] 2/-1/-1->0->-1 [3] 7/-1/-1->0->-1 [4] 7/-1/-1->0->-1 [5] 3/-1/-1->0->2 [6] 1/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 2/-1/-1->0->-1 [9] 7/-1/-1->0->-1 [10] 7/-1/-1->0->-1 [11] 3/-1/-1->0->2\n",
      "n192-025-207:289013:289306 [0] NCCL INFO P2P Chunksize set to 524288\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 00/0 : 6[6] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 06/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 06/0 : 6[6] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 07/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 00/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 06/0 : 3[3] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 01/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 06/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 07/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 01/0 : 0[0] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 02/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 07/0 : 0[0] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 08/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 06/0 : 5[5] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 02/0 : 4[4] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 01/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 03/0 : 4[4] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 02/0 : 2[2] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 02/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 08/0 : 4[4] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 08/0 : 2[2] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 07/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 09/0 : 4[4] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 02/0 : 3[3] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 08/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 08/0 : 3[3] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 05/0 : 4[4] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 02/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 01/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 11/0 : 4[4] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 05/0 : 5[5] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 05/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 02/0 : 7[7] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 11/0 : 5[5] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 03/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 07/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 08/0 : 7[7] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 03/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 08/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 11/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 03/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 05/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 09/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 05/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 09/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 01/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 09/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 11/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 05/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 11/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 07/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 11/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 03/0 : 0[0] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 03/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 01/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 04/0 : 0[0] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 04/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 05/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 09/0 : 0[0] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 09/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 07/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 10/0 : 0[0] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 10/0 : 2[2] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 11/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 10/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 04/0 : 7[7] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 10/0 : 7[7] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 04/0 : 6[6] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 10/0 : 6[6] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 04/0 : 4[4] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 09/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 10/0 : 4[4] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 10/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Connected all rings\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Connected all rings\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Connected all rings\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Connected all rings\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Connected all rings\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Connected all rings\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Connected all rings\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Connected all rings\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 03/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 05/0 : 6[6] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 03/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 04/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 11/0 : 6[6] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 09/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 04/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 09/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 09/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 04/0 : 3[3] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 10/0 : 4[4] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 05/0 : 5[5] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 10/0 : 2[2] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 10/0 : 3[3] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 11/0 : 5[5] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 10/0 : 7[7] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 05/0 : 0[0] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 01/0 : 4[4] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 03/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 05/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 11/0 : 0[0] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 07/0 : 4[4] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 04/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 05/0 : 2[2] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 02/0 : 4[4] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 01/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 11/0 : 1[1] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 09/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 11/0 : 2[2] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 08/0 : 4[4] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 04/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 10/0 : 5[5] -> 7[7] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 05/0 : 3[3] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 07/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 11/0 : 3[3] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 10/0 : 6[6] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 05/0 : 7[7] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 02/0 : 5[5] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 03/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 02/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 11/0 : 7[7] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 08/0 : 5[5] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 03/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 01/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 09/0 : 3[3] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 04/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 02/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 02/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 08/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 04/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 09/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 07/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 08/0 : 2[2] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 10/0 : 1[1] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 08/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 02/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 10/0 : 7[7] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 03/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 00/0 : 7[7] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 08/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 09/0 : 6[6] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 05/0 : 7[7] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 06/0 : 7[7] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 11/0 : 7[7] -> 6[6] via P2P/direct pointer\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 00/0 : 6[6] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 06/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 05/0 : 6[6] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 06/0 : 4[4] -> 3[3] via P2P/direct pointer\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 07/0 : 5[5] -> 4[4] via P2P/direct pointer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 06/0 : 6[6] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 11/0 : 6[6] -> 5[5] via P2P/direct pointer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Connected all trees\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Connected all trees\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Connected all trees\n",
      "n192-025-207:289013:289307 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-025-207:289013:289307 [1] NCCL INFO 12 coll channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-025-207:289013:289313 [7] NCCL INFO 12 coll channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 04/1 : 7[7] -> 1[1] via P2P/indirect/6[6]\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Connected all trees\n",
      "n192-025-207:289013:289310 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-025-207:289013:289310 [4] NCCL INFO 12 coll channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-025-207:289013:289306 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-025-207:289013:289306 [0] NCCL INFO 12 coll channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Connected all trees\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Connected all trees\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Connected all trees\n",
      "n192-025-207:289013:289308 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-025-207:289013:289308 [2] NCCL INFO 12 coll channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-025-207:289013:289309 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 04/1 : 2[2] -> 4[4] via P2P/indirect/5[5]\n",
      "n192-025-207:289013:289309 [3] NCCL INFO 12 coll channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-025-207:289013:289312 [6] NCCL INFO 12 coll channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 04/1 : 3[3] -> 5[5] via P2P/indirect/4[4]\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 04/1 : 6[6] -> 0[0] via P2P/indirect/7[7]\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Connected all trees\n",
      "n192-025-207:289013:289311 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "n192-025-207:289013:289311 [5] NCCL INFO 12 coll channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 05/1 : 7[7] -> 1[1] via P2P/indirect/6[6]\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 05/1 : 3[3] -> 5[5] via P2P/indirect/4[4]\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 05/1 : 6[6] -> 0[0] via P2P/indirect/7[7]\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 05/1 : 2[2] -> 4[4] via P2P/indirect/5[5]\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 12/1 : 7[7] -> 2[2] via P2P/indirect/0[0]\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 12/1 : 1[1] -> 4[4] via P2P/indirect/6[6]\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 12/1 : 3[3] -> 6[6] via P2P/indirect/1[1]\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 12/1 : 5[5] -> 0[0] via P2P/indirect/7[7]\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 13/1 : 1[1] -> 4[4] via P2P/indirect/6[6]\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 13/1 : 3[3] -> 6[6] via P2P/indirect/1[1]\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 13/1 : 7[7] -> 2[2] via P2P/indirect/0[0]\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 13/1 : 5[5] -> 0[0] via P2P/indirect/7[7]\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 02/1 : 4[4] -> 0[0] via P2P/indirect/7[7]\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 02/1 : 6[6] -> 2[2] via P2P/indirect/5[5]\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 02/1 : 1[1] -> 5[5] via P2P/indirect/6[6]\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 02/1 : 3[3] -> 7[7] via P2P/indirect/0[0]\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 02/1 : 2[2] -> 6[6] via P2P/indirect/1[1]\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 02/1 : 5[5] -> 1[1] via P2P/indirect/6[6]\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 02/1 : 7[7] -> 3[3] via P2P/indirect/0[0]\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 03/1 : 4[4] -> 0[0] via P2P/indirect/7[7]\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 02/1 : 0[0] -> 4[4] via P2P/indirect/3[3]\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 03/1 : 6[6] -> 2[2] via P2P/indirect/5[5]\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 03/1 : 1[1] -> 5[5] via P2P/indirect/6[6]\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 03/1 : 2[2] -> 6[6] via P2P/indirect/1[1]\n",
      "n192-025-207:289013:289309 [3] NCCL INFO Channel 03/1 : 3[3] -> 7[7] via P2P/indirect/0[0]\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 03/1 : 0[0] -> 4[4] via P2P/indirect/3[3]\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 10/1 : 2[2] -> 7[7] via P2P/indirect/0[0]\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 10/1 : 6[6] -> 3[3] via P2P/indirect/1[1]\n",
      "n192-025-207:289013:289313 [7] NCCL INFO Channel 03/1 : 7[7] -> 3[3] via P2P/indirect/0[0]\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 03/1 : 5[5] -> 1[1] via P2P/indirect/6[6]\n",
      "n192-025-207:289013:289312 [6] NCCL INFO Channel 11/1 : 6[6] -> 3[3] via P2P/indirect/1[1]\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 10/1 : 4[4] -> 1[1] via P2P/indirect/6[6]\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 10/1 : 0[0] -> 5[5] via P2P/indirect/7[7]\n",
      "n192-025-207:289013:289308 [2] NCCL INFO Channel 11/1 : 2[2] -> 7[7] via P2P/indirect/0[0]\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 11/1 : 4[4] -> 1[1] via P2P/indirect/6[6]\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 11/1 : 0[0] -> 5[5] via P2P/indirect/7[7]\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 06/1 : 4[4] -> 2[2] via P2P/indirect/3[3]\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 06/1 : 1[1] -> 7[7] via P2P/indirect/0[0]\n",
      "n192-025-207:289013:289307 [1] NCCL INFO Channel 07/1 : 1[1] -> 7[7] via P2P/indirect/0[0]\n",
      "n192-025-207:289013:289310 [4] NCCL INFO Channel 07/1 : 4[4] -> 2[2] via P2P/indirect/3[3]\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 06/1 : 5[5] -> 3[3] via P2P/indirect/2[2]\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 06/1 : 0[0] -> 6[6] via P2P/indirect/1[1]\n",
      "n192-025-207:289013:289311 [5] NCCL INFO Channel 07/1 : 5[5] -> 3[3] via P2P/indirect/2[2]\n",
      "n192-025-207:289013:289306 [0] NCCL INFO Channel 07/1 : 0[0] -> 6[6] via P2P/indirect/1[1]\n",
      "n192-025-207:289013:289308 [2] NCCL INFO comm 0x181801f0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 3d000 commId 0x813af0a1d5470656 - Init COMPLETE\n",
      "n192-025-207:289013:289312 [6] NCCL INFO comm 0x18197e80 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId b1000 commId 0x813af0a1d5470656 - Init COMPLETE\n",
      "n192-025-207:289013:289310 [4] NCCL INFO comm 0x1818c080 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 88000 commId 0x813af0a1d5470656 - Init COMPLETE\n",
      "n192-025-207:289013:289306 [0] NCCL INFO comm 0x181752f0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 1a000 commId 0x813af0a1d5470656 - Init COMPLETE\n",
      "n192-025-207:289013:289307 [1] NCCL INFO comm 0x1817a2f0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 1b000 commId 0x813af0a1d5470656 - Init COMPLETE\n",
      "n192-025-207:289013:289313 [7] NCCL INFO comm 0x1819dd80 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId b2000 commId 0x813af0a1d5470656 - Init COMPLETE\n",
      "n192-025-207:289013:289311 [5] NCCL INFO comm 0x18191f80 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 89000 commId 0x813af0a1d5470656 - Init COMPLETE\n",
      "n192-025-207:289013:289309 [3] NCCL INFO comm 0x18186180 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3e000 commId 0x813af0a1d5470656 - Init COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 05:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "wandb: ⭐️ View project at https://ml.byteintl.net/experiment/tracking/detail?Id=project_20230423_c364971e\n",
      "wandb: 🚀 View run at https://ml.byteintl.net/experiment/tracking/detail?Id=project_20230423_c364971e&selectedTrial=run_20240507_ffee0d5d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601655e71b4c453abb485e5b96e257af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668810260792574, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.72"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/tiger/network_attck/wandb/run-20240507_105048-run_20240507_ffee0d5d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"\" target=\"_blank\"></a></strong> to <a href=\"\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.026331692934036255,\n",
       " 'eval_accuracy': 0.99475478625754,\n",
       " 'eval_recall': 0.99475478625754,\n",
       " 'eval_runtime': 382.4576,\n",
       " 'eval_samples_per_second': 548.335,\n",
       " 'eval_steps_per_second': 0.086}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f31e4d34d90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3207402d90, execution_count=7 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f31a8200460, raw_cell=\"trainer.evaluate()\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://arnold-proxy-i18n.tiktok-row.org/opt/tiger/network_attck/fcbank.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D> result={'eval_loss': 0.026331692934036255, 'eval_accuracy': 0.99475478625754, 'eval_recall': 0.99475478625754, 'eval_runtime': 382.4576, 'eval_samples_per_second': 548.335, 'eval_steps_per_second': 0.086}>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
